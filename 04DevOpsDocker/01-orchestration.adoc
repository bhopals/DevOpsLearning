
==== Docker Swarm

Docker Swarm is open-source container orchestration platform and is the native clustering 
engine for and by Docker.

Docker Swarm is Cluster Management and Orchestration feature that build into the Docker Engine.

In Docker Swarm Cluster, worker nodes are being controlled by Swarm Manager Node.


====== To setup docker swarm cluster

    $ docker swarm init

    Swarm initialized: current node (56gohlzhrnfn5z5es8ikxs90x) is now a manager.


====== To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-2k65k4vnr7a72cxo1jm1ir7zdf2foj82pzs8u3dueuc3f4uncm-c7xuczrsqvx70hvm8mmxhyk3k \
    192.168.65.2:2377

======  To add a manager to this swarm, 

    run 'docker swarm join-token manager' and follow the instructions.


It will give you the token to use if you want to add more worker node
    
    docker swarm join-token  
    

It will give you the token to use if you want to add more manager node

    docker swarm join-manager 


Now run command "docker node ls". It will list out all the nodes that are running.

    $ docker node ls
    ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
    56gohlzhrnfn5z5es8ikxs90x *  moby      Ready   Active        Leader



===== Practical:

Use - https://labs.play-with-docker.com
For all the practicals.

If you are getting below error in Docker lab while running "docker swarm init" command, 
then use the <IP-Address> flag 

ERROR : docker swarm init could not choose an IP address error

    docker swarm init --advertise-addr <IP-ADDRESS>


===== Node / Service / Container / Tasks

Node - Node is your physical host or a virtual machine in the cloud thats running docker, the docker engine.

Task - Tasks are the container Images that are running across cluster. In a above example, TASK is  
webapp1 and CONTAINER is NGINX.


====== Container 

Any image that you want to deploy as a service in the swarm cluster.

The container runs only on one host, the host you instantited on when you perform "docker run" command.
It will share the network and other resources per container.

- Runs on one host
- Must share networks and storage per container, when run
- Containers are tough to scale and make highly available
- COMMAND - docker run <IMAGE-NAME>


====== Service

Service - Services are the instances of the image that run inside container.

    docker service create --name <app-name> --replicas=6 nginx
    docker service create --name webapp1 --replicas=6 nginx

- Automatically runs across however many nodes are needed.
- High availabilit simply builts in.
- COMMAND - docker service create --name <name> --replicas=6 <IMAGENAME>
- Scalability of the app is easy
- Exposing Network and Storage is easy


We do docker swarm init and run 3 nodes in cluster node. Then instantite nginx (a popular webserver's) 6 instances 
on all three nodes (2 instances each) in a clustered environment.

    NODE1 -> MANAGER  
    NODE2 -> WORKER 
    NODE3 -> WORKER
    NODE4 -> WORKER


    docker node ls (Output all the nodes running) - (Can only be executed on manager)
    docker service ls (List the service details and replicas)
    docker service ps (Will return the process / services running details)

Once run, If one of the node crashed, the services instances would be created on another node instantly.


Docker services are better way to run Containers because services allow you to run containers across 
tens or hundreds of nodes in a docker swarm cluster with scalability and high availability build in.



====== Locking a Swarm Cluster 
You can enable it by passing a parameter --autolock while initializing docker swarm.

The locking envolves saving of the keys on the storage for communication between all the nodes in clustered environment.
Also the logs access. To store and distribute keys across all the applications that uses docker.

    docker swarm init --autolock

For an existing docker swarm cluster which is running we use this command in MANAGER 

    docker swarm update --autolock=true 

    This will return a KEY. 


On worker node, we will simple restart all the nodes by running.
    sudo systemctl restart docker

    Now if you run command "docker node ls", it will ask for the key to unlock it.
    You can do it by running the command- "docker swarm unlock" and once prompted, enter the KEY.

To change key, we can run "docker swarm unlock-key --rotate


Quorum should be achieved in CLUSTER mode of swarm. This basically tells if you have n numbers of total nodes
then how many of the nodes would be manager to achieve less or almost zero fault tolerence.

Fault tolerance is the property that enables a system to continue operating properly in the event of the failure of 
(or one or more faults within) some of its components.

The Quorum algorithms basically are based on RAFT consensus Algorith.

By default Manager Nodes also shares the load of all the worked nodes, so sometimes 
if you want your manager nodes to only manage things and not involve in work load sharing then 
you need to run following command.

    docker node update --availability drain <NODE>



==== MANAGING DOCKER Swarm


docker node ls - List all the nodes 
docker info | more - Provide more information about the node.

If any node wants to leave the Swarm
    docker swarm leave --force

To Stop any service on docker
 
    sudo systemctl stop docker

To visualize docker swarn cluster.

https://github.com/dockersamples/docker-swarm-visualizer
Here have details about it. Copy the given command and paste that in one of the manager node to deploy our startup.

    docker run -it -d -p 8080:8080 -v /var/run/docker.sock:/var/run/docker.sock dockersamples/visualizer.

Once the command is completed, please run "docker ps", you will find the visualizer in the list

now run "ip addr" to get the ip address and get the IP address of the SERVICE. Append the port 8080 with ip address
and run that on the browser 
    
    http://127.0.0.1:8080/

To convert Manager to Worker and vice versa run promote/demote command


==== Analyzing docker services with docker inspect

docker node ls - Give you the list of the nodes

Now run "docker inspect <nodename>/containerID | more"

To get specific field details you can do grep

    docker inspect <nodename>/containerID | grep Replicas

    docker inspect <containerID> | grep IPAddress




=== STACK 

A Service defines one or more instances of a single image deployed on one or more machines (described 
by one entry in the services part of the docker-compose.yaml files).

A Stack defines a group of heterogeneous services (described by the whole yaml file).

A stack is a group of interrelated services that share dependencies, and can be orchestrated and scaled 
together. A single stack is capable of defining and coordinating the functionality of an entire 
application (though very complex applications may want to use multiple stacks).

To implement stack, first we need to create docker-composer.yml file and add all the details in it.
Once done we need to run "the stack. 

docker stack deploy -c docker-compose.yml <stackname>

docker stack ls (List out all the stacks/services delpoyed)

To modify stack (To modify number of replicas, no of instances, resourece allocation, network and storage Configuration):

    docker service ls
    docker service update --replicas=20 <service-name> (Dynmically, without updating compose file) - One way

Or Go to docker stack yml file and save. once done, run 
        
    docker stack deploy -c docker-compose.yml <stackname>

    docker service ps <SERVICE/STACK_NAME>

    docker service update - can be used to update the network port or other settings of the deployed service

==== Replicated v/s global services 

You can define the mode of the service at the time of service Creation

    docker service create --mode = global  

It will deploye one task/service every node (One node can have multiple containers) for example- virus scanning, agent scanning

    docker service create --mode = replicated 



==== LOGS 
    
    docker service logs

    docker service create --name <name-of-service> -p<incomingport>:<outboundport> <imagename>
    docker service create --name test-server -p8080:80 httpd

    docker service ls

    docker service logs <service-name>

    DOCKER CONTAINER NETWROKING MODEL.. ?? //NEED to READ 
    

    https://github.com/Evalle/DCA/blob/master/README.md#domain-1-orchestration-25-of-exam
        

=== Domain 1: Orchestration (25% of exam)

Complete the setup of a swarm mode cluster, with managers and worker nodes
Initializing SWARM container        
    $ docker swarm init --advertise-addr <MANAGER-IP>
  
    $ docker swarm join \
        --token  SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
        192.168.99.100:2377   

    $ docker swarm join-token worker (It will return token details to join as a worker)

    $ docker swarm join-token manager  (It will return token details to join as a manager)

    $ docker service create --replicas 1 --name helloworld alpine ping docker.com
        (To create and deploy service on Docker Container with replicas )


Publish a port for a service

    $ $ docker service create \
            --name <SERVICE-NAME> \
            --publish published=<PUBLISHED-PORT>,target=<CONTAINER-PORT> \
            <IMAGE>

    $ docker service inspect helloworld

Run docker service ps <SERVICE-ID> to see which nodes are running the service
    $ docker service ps helloworld

Run the following command to change the desired state of the service running in the swarm:

    $ docker service scale <SERVICE-ID>=<NUMBER-OF-TASKS>
    
    $ docker service scale helloworld=5 helloworld scaled to 5

    $ docker node update --label-add foo --label-add bar=baz node-1

    $ docker node promote node-3 node-2 (Worker to Manager Node )

    $ docker node demote node-3 node-2 (Manager to Worker Node)

    $ docker swarm leave

    $ docker node update --availability drain <NODE>


==== State the differences between running a container vs running a service
https://stackoverflow.com/questions/43408493/what-is-the-difference-between-docker-service-and-docker-container/43408904#43408904
   
Docker run is used to create a standalone container

Docker service create is used to create instances (called tasks) of that service running 
in a cluster (called swarm) of computers (called nodes). Those tasks are containers of cource, 
but not standalone containers. In a sense a service acts as a template when instantiating tasks.

===== Demonstrate steps to lock a swarm cluster
        
    $ docker swarm init --autolock
    $ docker swarm update --autolock=true
    $ docker swarm update --autolock=false
    $ docker swarm unlock-key
    $ docker swarm unlock-key --rotate
    
Extend the instructions to run individual containers into running services under swarm
Interpret the output of "docker inspect" commands
   
    
===== Convert an application deployment into a stack file using a YAML compose file with "docker stack deploy"

Docker File command SEQ : FROM --> WORKDIR --> COPY --> RUN --> EXPOSE --> ENV --> CMD 
    
    # Use an official Python runtime as a parent image
    FROM python:2.7-slim

    # Set the working directory to /app
    WORKDIR /app

    # Copy the current directory contents into the container at /app
    COPY . /app

    # Install any needed packages specified in requirements.txt
    RUN pip install --trusted-host pypi.python.org -r requirements.txt

    # Make port 80 available to the world outside this container
    EXPOSE 80

    # Define environment variable
    ENV NAME World

    # Run app.py when the container launches
    CMD ["python", "app.py"]


Docker File Build command :
    docker build --tag=friendlyhello .

For DNS Settigs :
    You can edit (or create) the configuration file at /etc/docker/daemon.json with the dns key 

To RUN:
    docker run -p 4000:80 friendlyhello


    $ docker login

SYNTAX:
    $ docker tag <image-name> <username>/<repository>:<tag>

EXAMPLE:
    $ docker tag friendlyhello gordon/get-started:part2

    $ docker push username/repository:tag

    $ docker run -p 4000:80 username/repository:tag

    $ docker stack deploy -c docker-compose.yml getstartedlab


==== Manipulate a running stack of services
        
    
===== Increase number of replicas
        
    $ docker service scale SERVICE=REPLICAS [SERVICE=REPLICAS...]

    $ docker service create --mode global --name backend backend:latest

    $ docker service scale frontend=50

    $ docker service ls --filter name=frontend


You can also scale a service using the docker service update command. The following commands are equivalent:

    $ docker service scale frontend=50
    $ docker service update --replicas=50 frontend


===== Docker Service Create 
            
    $ docker service create --name my-service -p 8080:80 nginx:alpine

    $ docker service update --replicas=3 my-service

    $ docker service rollback my-service


===== Illustrate running a replicated vs global service
- Mount volumes
- Add networks, publish ports
- Identify the steps needed to troubleshoot a service not deploying
- Apply node labels to demonstrate placement of tasks
- Sketch how a Dockerized application communicates with legacy systems
- Paraphrase the importance of quorum in a swarm cluster
- Demonstrate the usage of templates with "docker service create"



===== Other Details  
Open protocols and ports between the hosts
The following ports must be available. On some systems, these ports are open by default.
TCP port 2377 for cluster management communications
TCP and UDP port 7946 for communication among nodes
UDP port 4789 for overlay network traffic
If you plan on creating an overlay network with encryption (--opt encrypted), 
you also need to ensure ip protocol 50 (ESP) traffic is allowed


The swarm manager uses ingress load balancing to expose the services you want to make available 
externally to the swarm. The swarm manager can automatically assign the service a PublishedPort 
or you can configure a PublishedPort for the service. You can specify any unused port. 
If you do not specify a port, the swarm manager assigns the service a port in the 30000-32767 range.

An N manager cluster tolerates the loss of at most (N-1)/2 managers.

Worker nodes don’t participate in the Raft distributed state, make scheduling decisions, 
or serve the swarm mode HTTP API.

