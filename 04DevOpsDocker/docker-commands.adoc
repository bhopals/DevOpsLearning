
=== Docker Basic Commands 

    $ sudo docker pull -a busybox

Here -a flag ensures the fetching of all the variants (versions) of the image.
The "busybox" is the registry here.

    $ sudo docker pull busybox

If we dont pass this flag then docker will fetch only image which is tagged with latest.

But if tou want to download the image varient other than the latest then you need to pass the tag 
details along with the repository

    $ sudo docker pull busybox:ubuntu-10.2.3


===== To Search for any Docker image 
    
    $ sudo docker search mysql

    $ docker run -i -t ubunut:latest /bin/bash


Here once container is created, it will open a BASH and prompt for the command. 
The command variable we access the details of the IMAGE 

    /# id 

    /# hostname


===== Attach/Detach 

To detach any Docker from Container PRESS CTRL + P and CTRL + Q  in SEQUENCE 
To attach any container back (You can attach/detach any container as many times as you want)

    $ sudo docker attach <container-id>

    $ sudo docker run --name <custom-name> -t -i ubuntu:latest /bin/bash 

====== ATTACH: 

        $ sudo docker attach <container-name/id>

====== DETACH:

        Press CTRL+P and CTRL+Q in SEQUENCE


To see the changes we made in the docker image in the container 

    $ docker diff <img-id>


To test this scenario ..first run thi $ sudo docker run --name <custom-name> -t -i ubuntu:latest /bin/bash 
Once done, create some files in the bash by using "touch {a,b,c}.txt

Then press CTRL+P and CTRL+Q to detach from the container.

now run "docker diff <container-id>". It will return the changes that we made.


==== SIGTERM

SIGTERM (-15) - When a user issues this command, the Docker engine
sends SIGTERM (-15) to the main process, which is running inside the container.
The SIGTERM signal requests the process to terminate itself gracefully. Most of the
processes would handle this signal and facilitate a graceful exit. However, if this
process fails to do so, then the Docker engine will wait for a grace period. Even after
the grace period, if the process has not been terminated, then the Docker engine will
forcefully terminate the process. The forceful termination is achieved by sending
SIGKILL (-9). 


==== SIGKILL
SIGKILL (-9) - The SIGKILL signal cannot be caught or ignored, and so it will result
in an abrupt termination of the process without a proper clean-up.


    $ sudo container ps //List all the running containers 
    $ sudo container ps -a //List running and non running containers 


    $ cat Dockerfile
    FROM busybox:latest
    CMD echo Hello World!!

    $ sudo docker build .

    $ sudo docker image ls 

    $ sudo docker run 0a2abe57c325
    Hello World!!

===== To add tag name 
    
    $ sudo docker tag 0a2abe57c325 busyboxplus


The alternative approach is to build the image with an image name during the build
time by using the -t option for the docker build subcommand, as shown here:
$ sudo docker build -t busyboxplus .



== Dockerfile 

    The Dockerfile build instructions - 

        The instruction line of Dockerfile is made up of two components, where the
        instruction line begins with the instruction itself, which is followed by the arguments
        for the instruction. The instruction could be written in any case, in other words, it is
        case-insensitive. However, the standard practice or convention is to use uppercase in
        order to differentiate it from the arguments. Let's take another look at the content of
        Dockerfile in our previous example:
        
        ``
            FROM busybox:latest
            CMD echo Hello World!!
        ``
        
        Here, FROM is an instruction which has taken busybox:latest as an argument,
        and CMD is an instruction which has taken echo Hello World!! as an argument.


  ====  FROM 

  The FROM instruction has the following syntax:
        FROM <image>[:<tag>]
        In the preceding code statement, note the following:
        • <image>: This is the name of the image which will be used as the base image.
        • <tag>: This is the optional tag qualifier for that image. If any tag qualifier has
        not been specified, then the tag latest is assumed.
        Here is an example of the FROM instruction with the image name centos:
       
        FROM centos 

        Docker Allow multiple FROM Instructions 


  ====    COMMENT:

            The comment line in Dockerfile must begin with the # symbol. The # symbol
            after an instruction is considered as an argument. If the # symbol is preceded by
            a whitespace, then the docker build system would consider that as an unknown
            instruction and skip the line. Now, let's better understand these mentioned cases
            with the help of an example to get a better understanding of the comment line:
            
            • A valid Dockerfile comment line always begins with a # symbol as the
            first character of the line:
            
            # This is my first Dockerfile comment
            
            
            • The # symbol can be a part of an argument:
            CMD echo ### Welcome to Docker ###
            
            
            • If the # symbol is preceded by a whitespace, then it is considered as an
            unknown instruction by the build system:
                 # this is an invalid comment line

==== MAINTAINER 

    MAINTAINER <Author name/email address>

    Should be placed after FROM instruction.


==== COPY  

    The COPY instruction enables you to copy the files from the Docker host to the
    filesystem of the new image. The following is the syntax of the COPY instruction:
    
    COPY <src> ... <dst>
    
    The preceding code terms bear the explanations shown here:
    
        • <src>: This is the source directory, the file in the build context, or the
            directory from where the docker build subcommand was invoked.
    
        • ...: This indicates that multiple source files can either be specified
                directly or be specified by wildcards.
        
        • <dst>: This is the destination path for the new image into which the source
            file or directory will get copied. If multiple files have been specified, then the
            destination path must be a directory and it must end with a slash /.

==== ADD 

    The ADD instruction is similar to the COPY instruction. However, in addition to
    the functionality supported by the COPY instruction, the ADD instruction can handle
    the TAR files and the remote URLs. We can annotate the ADD instruction as COPY
    on steroids.
    The following is the syntax of the ADD instruction:
    ADD <src> ... <dst>


==== ENV
    The ENV instruction sets an environment variable in the new image. An environment
    variable is a key-value pair, which can be accessed by any script or application. The
    Linux applications use the environment variables a lot for a starting configuration.
    The following line forms the syntax of the ENV instruction:
    ENV <key> <value>
    Here, the code terms indicate the following:
        • <key>: This is the environment variable
        • <value>: This is the value that is to be set for the environment variable

    ENV DEBUG_LVL 3
    ENV APACHE_LOG_DIR /var/log/apache

==== USER
    The USER instruction sets the start up user ID or user Name in the new image.
    By default, the containers will be launched with root as the user ID or UID.
    Essentially, the USER instruction will modify the default user ID from root to
    the one specified in this instruction.
    The syntax of the USER instruction is as follows:
    USER <UID>|<UName>
    The USER instructions accept either <UID> or <UName> as its argument:
    • <UID>: This is a numerical user ID
    • <UName>: This is a valid user Name
    The following is an example for setting the default user ID at the time of startup to
    73. Here 73 is the numerical ID of the user:
    USER 73


==== WORKDIR 

    The WORKDIR instruction changes the current working directory from / to the
    path specified by this instruction. The ensuing instructions, such as RUN, CMD,
    and ENTRYPOINT will also work on the directory set by the WORKDIR instruction.
    The following line gives the appropriate syntax for the WORKDIR instruction:
    WORKDIR <dirpath>
    Here, <dirpath> is the path for the working directory to set in. The path can be
    either absolute or relative. In case of a relative path, it will be relative to the previous
    path set by the WORKDIR instruction. If the specified directory is not found in the
    target image filesystem, then the director will be created.
    The following line is a clear example of the WORKDIR instruction in a Dockerfile:
    
    WORKDIR /var/log


==== VOLUME
    The VOLUME instruction creates a directory in the image filesystem, which can later be
    used for mounting volumes from the Docker host or the other containers.
    The VOLUME instruction has two types of syntax, as shown here:
    
    • The first type is either exec or JSON array (all values must be within doublequotes
    (")):
        VOLUME ["<mountpoint>"]
    
    • The second type is shell, as shown here:
        VOLUME <mountpoint>
    
    In the preceding line, <mountpoint> is the mount point that has to be created
    in the new image.


====  EXPOSE

    The EXPOSE instruction opens up a container network port for communicating
    between the container and the external world.
    The syntax of the EXPOSE instruction is as follows:

    EXPOSE <port>[/<proto>] [<port>[/<proto>]...]

    Here, the code terms mean the following:
        • <port>: This is the network port that has to be exposed to the outside world.
        • <proto>: This is an optional field provided for a specific transport protocol,
            such as TCP and UDP. If no transport protocol has been specified, then TCP
            is assumed to be the transport protocol.
    
    The EXPOSE instruction allows you to specify multiple ports in a single line.

    The following is an example of the EXPOSE instruction inside a Dockerfile exposing
    the port number 7373 as a UDP port and the port number 8080 as a TCP port. As
    mentioned earlier, if the transport protocol has not been specified, then the TCP
    transport is assumed to be the transport protocol:
    
    EXPOSE 7373/udp 8080

    If Protocol not provided then by default TCP is set.


==== RUN


    The RUN instruction is the real workhorse during the build time, and it can run any
    command. The general recommendation is to execute multiple commands by using
    one RUN instruction. This reduces the layers in the resulting Docker image because
    the Docker system inherently creates a layer for each time an instruction is called in
    Dockerfile.
    The RUN instruction has two types of syntax:

        • The first is the shell type, as shown here:
            
            RUN <command>
            
            Here, the <command> is the shell command that has to be executed during the
            build time. If this type of syntax is to be used, then the command is always
            executed by using /bin/sh -c.

        • The second syntax type is either exec or the JSON array, as shown here:
            RUN ["<exec>", "<arg-1>", ..., "<arg-n>"]
            Within this, the code terms mean the following:


        Example :
        RUN echo "echo Welcome to Docker!" >> /root/.bashrc


==== CMD 


    The CMD instruction can run any command (or application), which is similar to the RUN
    instruction. However, the major difference between those two is the time of execution.
    The command supplied through the RUN instruction is executed during the build time,
    whereas the command specified through the CMD instruction is executed when the
    container is launched from the newly created image. Therefore, the CMD instruction
    provides a default execution for this container. However, it can be overridden by the
    docker run subcommand arguments. When the application terminates, the container
    will also terminate along with the application and vice versa.

    The CMD instruction has three types of syntax, as shown here:

        • The first syntax type is the shell type, as shown here:
        CMD <command>
        Within this, the <command> is the shell command, which has to be executed
        during the launch of the container. If this type of syntax is used, then the
        command is always executed by using /bin/sh -c.

        • The second type of syntax is exec or the JSON array, as shown here:
        CMD ["<exec>", "<arg-1>", ..., "<arg-n>"]
        Within this, the code terms mean the following:
            °° <exec>: This is the executable, which is to be run during the
            container launch time.
            °° <arg-1>, ..., <arg-n>: These are the variable (zero or more)
            numbers of the arguments for the executable.
            Building Images
            [ 52 ]

        • The third type of syntax is also exec or the JSON array, which is similar to the
        previous type. However, this type is used for setting the default parameters
        to the ENTRYPOINT instruction, as shown here:
        CMD ["<arg-1>", ..., "<arg-n>"]
        Within this, the code terms mean the following:
            °° <arg-1>, ..., <arg-n>: These are the variable (zero or more)
            numbers of the arguments for the ENTRYPOINT instruction, which
         will be explained in the next section.

    === HEALTHCHECK
        To check the health of the app running into the container.

        Example: 
        HEALTHCHECK --interval=5s --timeout=3s CMD curl --fails
        http://localhost:8091/pools || exit 1

    
    == USER - Sets the username or UID to use when running the image .
    

==== Sample Docker File 

########################################################
# Dockerfile to demonstrate the behaviour of CMD
########################################################
# Build from base image busybox:latest
FROM busybox:latest
# Author: Dr. Peter
MAINTAINER Dr. Peter <peterindia@gmail.com>
# Set command for CMD
CMD ["echo", "Dockerfile CMD demo"]

$ sudo docker build -t cmd-demo .

$ sudo docker run cmd-demo
Dockerfile CMD demo

Cool, isn't it? We have given a default execution for our container and our container
has faithfully echoed Dockerfile CMD demo. However, this default execution can be
easily overridden by passing another command as an argument to the docker run
subcommand, as shown in the following example:

$ sudo docker run cmd-demo echo Override CMD demo
Override CMD demo




==== ENTRYPOINT

    The ENTRYPOINT instruction will help in crafting an image for running an application
    (entry point) during the complete life cycle of the container, which would have
    been spun out of the image. When the entry point application is terminated, the
    container would also be terminated along with the application and vice versa.
    Therefore, the ENTRYPOINT instruction would make the container function like an
    executable. Functionally, ENTRYPOINT is akin to the CMD instruction, but the major
    difference between the two is that the entry point application is launched by using
    the ENTRYPOINT instruction, which cannot be overridden by using the docker run
    subcommand arguments. However, these docker run subcommand arguments will
    be passed as additional arguments to the entry point application. Having said this,
    Docker provides a mechanism for overriding the entry point application through the
    --entrypoint option in the docker run subcommand. The --entrypoint option
    can accept only word as its argument, and so it has limited functionality.

==== ONBUILD 

    The ONBUILD instruction registers a build instruction to an image and this
    is triggered when another image is built by using this image as its base image.
    Any build instruction can be registered as a trigger and those instructions will be
    triggered immediately after the FROM instruction in the downstream Dockerfile.
    Therefore, the ONBUILD instruction can be used to defer the execution of the build
    instruction from the base image to the target image.

    The syntax of the ONBUILD instruction is as follows:
    ONBUILD <INSTRUCTION>
    Within this, <INSTRUCTION> is another Dockerfile build instruction, which will
    be triggered later. The ONBUILD instruction does not allow the chaining of another
    ONBUILD instruction. In addition, it does not allow the FROM and MAINTAINER
    instructions as ONBUILD triggers.
    Here is an example of the ONBUILD instruction:
    ONBUILD ADD config /etc/appconfig

    So It will have another instruction passed in.


==== The .dockerignore file

     we learnt that the docker build process will send the complete build context to the daemon. To ignore that, we have dockerignore file.


Docker history subcommand is an excellent and handy tool for visualizing the image layers.
$ sudo docker history <docker-id>

VMWARE Alternative Boot and Delete Option 
https://stackoverflow.com/questions/39858200/vmware-workstation-and-device-credential-guard-are-not-compatible




=== Docker hub Image registry

    Docker Registry is a storage system used to store the images.

    $ sudo docker login (Command to login into docker hub from cmd prompt) 


    Create a container 
    $ sudo docker run -i --name="containerforhub" -t ubuntu /bin/bash
    root@e3bb4b138daf:/#
    Next, we'll create a new directory and file in the containerforhub container.
    We will also update the new file with some sample text to test later:
    
    root@bd7cc5df6d96:/# mkdir mynewdir
    
    root@bd7cc5df6d96:/# cd mynewdir
    
    root@bd7cc5df6d96:/mynewdir# echo 'this is my new container to make
    image and then push to hub' >mynewfile
    
    root@bd7cc5df6d96:/mynewdir# cat mynewfile
    This is my new container to make image and then push to hub
    
    root@bd7cc5df6d96:/mynewdir#
    
    Let's build the new image with the docker commit command from the container,
    which has just been created. Note that the commit command would be executed
    from the host machine, from where the container is running, and not from inside
    this container:
    
    $ sudo docker commit -m="NewImage" containerforhub vinoddandy/imageforhub
    3f10a35019234af2b39d5fab38566d586f00b565b99854544c4c698c4a395d03

    Here "containerforhub" is the container ID on which we made the changes.


    $ docker run -p 5050:5050 registry //To install Registry on localhost


    Here is a slightly more complex example that launches a registry on port 5000, using an Amazon S3 bucket to store images with a custom path, and enables the search endpoint:

    $ docker run \
            -e SETTINGS_FLAVOR=s3 \
            -e AWS_BUCKET=mybucket \
            -e STORAGE_PATH=/registry \
            -e AWS_KEY=myawskey \
            -e AWS_SECRET=myawssecret \
            -e SEARCH_BACKEND=sqlalchemy \
            -p 5000:5000 \
            registry



==== Automating the build process for Images

    Here we can connect our github account to docker hub to automate the build process.
    Once enabled, go to especific REPOSITORY and linked that with any branch.


    So, whenever the Dockerfile is updated in GitHub, the automated build gets
    triggered, and a new image will be stored in the Docker Hub Registry. We can
    always check the build history. We can change the Dockerfile on the local machine
    and push to GitHub. Then, we can see the automated build link of the Docker Hub
    at https://registry.hub.docker.com/u/vinoddandy/dockerautomatedbuild/
    builds_history/82194/.


==== Public and Private repository

    Let's create a repository in the local machine using the registry image provided by
    Docker. We will run the registry container on the local machine, using the registry
    image from Docker:
    
    $ sudo docker run -p 5000:5000 -d registry
    768fb5bcbe3a5a774f4996f0758151b1e9917dec21aedf386c5742d44beafa41
    
    Once Local registry server is up, we can tag any image and push that to local repository
    
    This tag will help you identify the particular image:
    $ sudo docker tag
    224affbf9a65localhost:5000/vinoddandy/dockerfileimageforhub
    
    Once the tagging is done, push this image to a new registry using the docker push
    command:
    $ sudo docker push localhost:5000/vinoddandy/dockerfile
    imageforhub

    
    ===== Docker hub Rest API 

    The REST APIs for the Docker Hub
    The Docker Hub provides a REST API to integrate the Hub capabilities through
    programs. The REST API is supported for both user as well as repository
    management.
    User management supports the following features:
    
    • User Login: This is used for user login to the Docker Hub:
        GET /v1/users
        $ curl --raw -L --user vinoddandy:password
        https://index.docker.io/v1/users
        4
        "OK"
        0
    
    • User Register: This is used for registration of a new user:
        POST /v1/users

    • Create User repositories
    curl --raw -L -X POST --post301 -H "Accept:application/json"
    -H "Content-Type: application/json" --data-ascii '{"email":
    "singh_vinod@yahoo.com", "password": "password", "username":
    "singhvinod494" }' https://index.docker.io/v1/users

    Delete a user repository: This deletes a user repository:
    
    DELETE /v1/repositories/(namespace)/(repo_name)/
    • Create a library repository: This creates the library repository, and it is
    available only to Docker administrators:
    PUT /v1/repositories/(repo_name)/

    • Delete a library repository: This deletes the library repository, and it is
    available only to Docker administrators:
    DELETE /v1/repositories/(repo_name)/
    
    • Update user repository images: This updates the images of a user's
    repository:
    PUT /v1/repositories/(namespace)/(repo_name)/images




=== Running your private Docker Infrastructure 

    Primarily, a Docker Hub is specially made to centralize and centrally manage information on:
        • User accounts
        • Checksums of the images
        • Public namespaces

   The Docker Registry and Index 
        A Docker hub consist of Docker Registry and Index 

        The advanced features of the Docker registry include bugsnag, new relic, and cors.


===== Publishing container ports – the -p option

The -p option,
    actually, supports the following four formats of arguments:
    • <hostPort>:<containerPort>
    • <containerPort>
    • <ip>:<hostPort>:<containerPort>
    • <ip>::<containerPort>

===== Network Address Translation for containers
        In the previous section, we saw how a -p 80:80 option did the magic, didn't it?
        Well, in reality, under the hood, the Docker engine achieves this seamless
        connectivity by automatically configuring the Network Address Translation (NAT)
        rule in the Linux iptables configuration files.

===== Binding a container to a specific IP address
    $ sudo docker run -d -p 198.51.100.73:80:80 apache2
    92f107537bebd48e8917ea4f4788bf3f57064c8c996fc23ea0fd8ea49b4f3335


=== Sharing Data with Containers 


In this chapter, we will cover the following topics:


==== Data volume

    Image are part of Union filesystem. However, the data volume is part of the Docker host filesystem, and it simply gets
    mounted inside the container

    A data volume can be inscribed in a Docker image using the VOLUME instruction of
    the Dockerfile. 
    
    VOLUME /MountDemo 


    Also, it can be prescribed during the launch of a container using
    the -v option of the docker run subcommand.
    $ sudo docker run –v /MountPointDemo -it ubuntu:14.04
    

    $ sudo docker run --rm -it mount-point-demo
    --rm -> Remove the container once exits

   

   In both the scenarios described here, the Docker engine automatically creates the
    directory under /var/lib/docker/vfs/ and mounts it to the container. When a
    container is removed using the docker rm subcommand, the Docker engine does
    not remove the directory that was automatically created during the container launch
    time. This behavior is innately designed to preserve the state of the container's
    application that was stored in the directory. If you want to remove the directory that
    was automatically created by the Docker engine, you can do so while removing the
    container by providing a -v option to the docker rm subcommand, on an already
    stopped container:

    $ sudo docker rm -v 8d22f73b5b46
    $ sudo docker rm -vf 8d22f73b5b46 (Forced Removal)


==== Sharing host data

The –v option has three different formats
enumerated as follows:
1. -v <container mount path>
2. -v <host path>/<container mount path>
3. -v <host path>/<container mount path>:<read write mode>

First, let's launch an interactive container with the –v option of the docker
run subcommand to mount /tmp/hostdir of the Docker host directory to
/MountPoint of the container:
$ sudo docker run -v /tmp/hostdir:/MountPoint \
-it ubuntu:14.04

==== Sharing data between containers

===== Mount Data Volume from other container
    $ sudo docker run -d -p 80:80 \
        --volumes-from log_vol \
        apache2

    By doing this we can make the data avaialbe for both containers as both are pointing to the same Data Volume 

==== The avoidable common pitfalls


   ===== Directory leaks
        Earlier in the data volume section, we learnt that the Docker engine automatically
        creates directories based on the VOLUME instruction in Dockerfile as well as the
        -v option of the docker run subcommand. We also understood that the Docker
        engine does not automatically delete these auto-generated directories in order to
        preserve the state of the application(s) run inside the container.

  ===== The undesirable effect of data volume
        As mentioned earlier, Docker enables us to etch data volumes in a Docker image
        using the VOLUME instruction during the build time. Nonetheless, the data volumes
        should never be used to store any data during the build time, otherwise it will result
        in an unwanted effect.

        Example :

        1. Build the image using Ubuntu 14.04 as the base image:
        # Use Ubuntu as the base image
        FROM ubuntu:14.04
        2. Create a /MountPointDemo data volume using the VOLUME instruction:
        VOLUME /MountPointDemo
        3. Create a file in the /MountPointDemo data volume using the RUN instruction:
        RUN date > /MountPointDemo/date.txt






=== Orchestration

    <service>:
    <key>: <value>
    <key>:   
        - <value>
            Here, <service> is the name of the service. You can have more than one service
            definition in a single docker-compose.yml file. The service name should be followed
            by one or more keys. However, all the services must either have an image or a
            build key, followed by any number of optional keys. Except the image and build
            keys, the rest of the keys can be directly mapped to the options in the docker run
            subcommand. The value can be either a single value or multiple values.
            The following is a list of keys supported in the docker-compose version 1.2.0:
            • image: This is the tag or image ID
            • build: This is the path to a directory containing a Dockerfile
            • command: This key overrides the default command
            • links: This key links to containers in another service
            • external_links: This key links to containers started either by some other
            docker-compose.yml or by some other means (not by docker-compose)
            Chapter 8
            [ 143 ]
            • ports: This key exposes ports and specifies both the ports
            HOST_port:CONTAINER_port
            • expose: This key exposes ports without publishing them to the host machine
            • volumes: This key mounts paths as volumes
            • volumes_from: This key mounts all of the volumes from another container
            • environment: This adds environment variables and uses either an array or a
            dictionary
            • env_file: This adds environment variables to a file
            • extends: This extends another service defined in the same or different
            configuration file
            • net: This is the networking mode, which has the same values as the Docker
            client --net option
            • pid: This enables the PID space sharing between the host and the containers
            • dns: This sets custom DNS servers
            • cap_add: This adds a capability to the container
            • cap_drop: This drops a capability of the container
            • dns_search: This sets custom DNS search servers
            • working_dir: This changes the working directory inside the container
            • entrypoint: This overrides the default entrypoint
            • user: This sets the default user
            • hostname: This sets a container's host name
            • domainname: This sets the domain name
            • mem_limit: This limits the memory
            • privileged: This gives extended privileges
            • restart: This sets the restart policy of the container
            • stdin_open: This enables the standard input facility
            • tty: This enables text based control such as a terminal
            • cpu_shares: This sets the CPU shares (relative weight)


==== The Docker exec command
    
    The docker exec command provided the much-needed help to users, who are
    deploying their own web servers or other applications running in the background.
    Now, it is not necessary to log in to run the SSH daemon in the container.
    
    First, run the docker ps -a command to get the container ID:
    $ sudo docker ps -a
    b34019e5b5ee nsinit:latest "make local"
    a245253db38b training/webapp:latest "python app.py"
    
    Then, run the docker exec command to log in to the container.
    $ sudo docker exec -it a245253db38b bash
    root@a245253db38b:/opt/webapp#


### The security features of containers

    ##### Resource isolation

        The kernel namespaces guarantee the much-needed isolation feature for Linux
        containers. The Docker project has added a few additional namespaces for Docker
        containers, and each distinct aspect of a container runs in its own namespace and
        hence, does not have access outside it. The following is a list of namespaces that
        Docker uses:
        • The PID namespace: This is used for a series of actions taken in order to
        achieve process-level isolation
        • The Network namespace: This is used to have executive control over the
        network interfaces
        • The IPC namespace: This is used to maintain control over access to IPC
        resources
        • The Mount namespace: This is used to manage mount points
        • The UTS namespace: This is used to segregate the kernel and version
        identifiers

    ##### Resource accounting and control


    Copy-on-write filesystems: Docker has been using Advanced Multilayered
        unification Filesystem (AuFS) as a filesystem for containers. AuFS
        is a layered filesystem that can transparently overlay one or more existing
        filesystems. When a process needs to modify a file, AuFS first creates a
        copy of that file and is capable of merging multiple layers into a single
        representation of a filesystem. This process is called copy-on-write, and this
        prevents one container from seeing the changes of another container even
        if they write to the same filesystem image. One container cannot change the
        image content to affect the processes in another container