

https://github.com/Evalle/DCA

https://www.whizlabs.com/docker-certified-associate/

https://evalle.xyz/posts/


===================================================================================================
     Learning Docker
===================================================================================================

Docker is a tool that can package an application and its dependencies in a virtual container that can run on any Linux server

Docker is a set of coupled software-as-a-service and platform-as-a-service products that use operating-system-level virtualization to develop and deliver software in packages called containers. The software that hosts the containers is called Docker Engine. 
https://labs.play-with-docker.com/


Docker is a tool that can package an application and its dependencies in a virtual container that can run on any Linux server. 


Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers. The use of Linux containers to deploy applications is called containerization. Containers are not new, but their use for easily deploying applications is.

container - A container is a runtime instance of an image



COMMANDS :

docker run <image-name>
docker ps  (will return all the running systems.)
docker ps -a (to see all the containers including stopped ones)
docker ps -l (last exited container)
docker image ls (List out all the images)

docker run <image-name> (It takes image to the container)
docker commit <container-id> (it takes container back to new image. The command will return ID)
docker tag <ID> <custom-name-of-image> (this will put the name of the newly created image)


docker container have main process. Once the process finish, container stops.

docker attach <container-name>

docker exec (Add another process to the container)


docker kill <container-name> (Kill the container)
docker rm <container-name> (Remove the container)






===================================================================================================
    Chapter 1 - Docker Essential Training: 1 Installation and Configuration
===================================================================================================

DOCKER ENGINE : 

    Client - Docker Cli - (From where you execute the command.)
    Rest API - REGISTRY (docker hub)

When you run "docker run hello-world" on the command prompt, following things happened:


To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.


Docker Universal Control Panel (UCP):
  Only comes with docker EE version (Enterprise Edition)
  It helps us to manage multiple nodes/machine with docker engine running

  UCP provides below features:
    - Private image Registry called Docker Trusted Registry
    - Secure and access use Management
    - Application and cluster Management
    - Image security scanning and continuous monitoring
    - Content trust and verification
    - Policy Management


Docker user Namespace for container isolation.
Moreover, Docker also uses CGroups (Control Groups) for controlling container resources, primarily around CPU and Memory.


To Run Ubuntu Images:
docker container run -it ubuntu



Docker Public Repository - Docker hub

To login into docker hub.

Configuration
-------------------
run "docker login"
It will ask for username and password. Once successfully logged in, pull sample images to local from public dockerhub repository.

    docker pull <image-name>
    docker pull alphine

Once the image is downloaded, you can check by running "docker images". It will list out all the images/repository.

Now we will tag the downloaded image with some other id.

    docker tag <first_three_letter_of_image_id> <username>/<image-name/repository-name>:<newtagname>

    docker tag af0 bhopalsingh/alphine:linkedtag1
    docker tag af0 bhopalsingh/alphine:linkedtag2
    docker tag af0 bhopalsingh/alphine:linkedtag3

Here we have created 3 copies of the same repository.

Now we need to push these repositories up to Docker Hub, and to do that, execute following command.

    docker push <username>/<repository-name>
    docker push bhopalsingh/alphine



To delete docker images 
    docker images (it will list out all the Images)
    docker image rm <first_three_letter_of_image_id> -f 

Once deleted, we can fetch the copy from docker hub by

    docker pull <username>/<repository-name>:<tagname>
    docker pull bhopalsingh/alphine:linkedin1

So above demo was about: (push and pull images back and forth)
    - creating a docker repositories on local
    - push the repository to docker Hub
    - pull it back to local


Docker Universal Control Plane (UCP)

To Back up DOCKER, we need to take back up of following things:

    - Docker Swarm Cluster
    - Universal Control Plane (UCP)
    - Docker Truster Registry (DTR)
    - Container Volume Data

    

Install DTR - Docker Trusted Registry

docker run -it --rm docker/dtr:2.4.12 install --ucp-insecure-tls


Some useful commands to know the staus of your docker command.

    docker info
    docker version
    docker ps
    docker ps -a 
    

===================================================================================================
    Chapter 2 - Docker Essential Training: 2 Orchestration
===================================================================================================


Docker Swarm
-----------------
Docker Swarm is open-source container orchestration platform and is the native clustering engine for and by Docker.

Docker Swarm is Cluster Management and Orchestration feature that build into the Docker Engine.

In Docker Swarm Cluster, worker nodes are being controlled by Swarm Manager Node.


To setup docker swarm cluster, "docker swarm init" command.
C:\Users\<UserName>>docker swarm init
Swarm initialized: current node (56gohlzhrnfn5z5es8ikxs90x) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-2k65k4vnr7a72cxo1jm1ir7zdf2foj82pzs8u3dueuc3f4uncm-c7xuczrsqvx70hvm8mmxhyk3k \
    192.168.65.2:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.


docker swarm join-token  = it will give you the token to use if you want to add more worker node
docker swarm join-manager= it will give you the token to use if you want to add more manager node

Now run command "docker node ls". It will list out all the nodes that are running.

C:\Users\<UserName>>docker node ls
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
56gohlzhrnfn5z5es8ikxs90x *  moby      Ready   Active        Leader



Practical:
-----------------------
Use - https://labs.play-with-docker.com
For all the practicals.

If you are getting below error in Docker lab while running "docker swarm init" command, then use the <IP-Address> flag
ERROR : docker swarm init could not choose an IP address error

docker swarm init --advertise-addr <IP-ADDRESS>


NODE / SERVICE / CONTAINER / TASKS

NODE - Node is your physical host or a virtual machine in the cloud thats running docker, the docker engine.

SERVICE - SERVICES are the instances of the image that run inside container.

    docker service create --name <app-name> --replicas=6 nginx
    docker service create --name webapp1 --replicas=6 nginx

TASK - Tasks are the container Images that are running across cluster. In a above example, TASK is  
webapp1 and CONTAINER is NGINX.

CONTAINER - Any image that you want to deploy as a service in the swarm cluster.

The container runs only on one host, the host you instantited on when you perform "docker run" command.
It will share the network and other resources per container.

CONTAINER :
    - Runs on one host
    - Must share networks and storage per container, when run
    - Containers are tough to scale and make highly available
    - COMMAND - docker run <IMAGE-NAME>
SERVICE : 
    - Automatically runs across however many nodes are needed.
    - High availabilit simply builts in.
    - COMMAND - docker service create --name <name> --replicas=6 <IMAGENAME>
    - Scalability of the app is easy
    - Exposing Network and Storage is easy


We do docker swarm init and run 3 nodes in cluster node. Then instantite nginx (a popular webserver's) 6 instances 
on all three nodes (2 instances each) in a clustered environment.

NODE1 - MANAGER  
NODE2 - WORKER 
NODE3 - WORKER
NODE4 - WORKER

docker node ls (Output all the nodes running) - (Can only be executed on manager)
docker service ls (List the service details and replicas)
docker service ps (Will return the process / services running details)

Once run, If one of the node crashed, the services instances would be created on another node instantly.


Docker services are better way to run Containers because services allow you to run containers across 
tens or hundreds of nodes in a docker swarm cluster with scalability and high availability build in.



Locking a Swarm Cluster - You can enable it by passing a parameter --autolock while initializing docker swarm.

    The locking envolves saving of the keys on the storage for communication between all the nodes in clustered environment.
    Also the logs access. To store and distribute keys across all the applications that uses docker.

    docker swarm init --autolock

For an existing docker swarm cluster which is running we use this command in MANAGER 

    docker swarm update --autolock=true 

    This will return a KEY. 


On worker node, we will simple restart all the nodes by running.
    sudo systemctl restart docker

    Now if you run command "docker node ls", it will ask for the key to unlock it.
    You can do it by running the command- "docker swarm unlock" and once prompted, enter the KEY.

To change key, we can run "docker swarm unlock-key --rotate


Quorum should be achieved in CLUSTER mode of swarm. This basically tells if you have n numbers of total nodes
then how many of the nodes would be manager to achieve less or almost zero fault tolerence.

Fault tolerance is the property that enables a system to continue operating properly in the event of the failure of (or one or more faults within) some of its components.

The Quorum algorithms basically are based on RAFT consensus Algorith.

By default Manager Nodes also shares the load of all the worked nodes, so sometimes 
if you want your manager nodes to only manage things and not involve in work load sharing then 
you need to run following command.

    docker node update --availability drain <NODE>



MANAGING DOCKER Swarm
-----------------------------------

docker node ls - List all the nodes 
docker info | more - Provide more information about the node.

If any node wants to leave the Swarm
    docker swarm leave --force

To Stop any service on docker
 
    sudo systemctl stop docker

To visualize docker swarn cluster.

    https://github.com/dockersamples/docker-swarm-visualizer
    Here have details about it. Copy the given command and paste that in one of the manager node to deploy our startup.

    docker run -it -d -p 8080:8080 -v /var/run/docker.sock:/var/run/docker.sock dockersamples/visualizer.

    Once the command is completed, please run "docker ps", you will find the visualizer in the list

    now run "ip addr" to get the ip address and get the IP address of the SERVICE. Append the port 8080 with ip address
    and run that on the browser 
    http://127.0.0.1:8080/

To convert Manager to Worker and vice versa run promote/demote command


Analyzing docker services with docker inspect
----------------------------------------------------

docker node ls - Give you the list of the nodes

Now run "docker inspect <nodename>/containerID | more"

To get specific field details you can do grep

    docker inspect <nodename>/containerID | grep Replicas

    docker inspect <containerID> | grep IPAddress




STACK 
-------------------------------
A Service defines one or more instances of a single image deployed on one or more machines (described by one entry in the services part of the docker-compose.yaml files).


A Stack defines a group of heterogeneous services (described by the whole yaml file).

A stack is a group of interrelated services that share dependencies, and can be orchestrated and scaled together. A single stack is capable of defining and coordinating the functionality of an entire application (though very complex applications may want to use multiple stacks).

To implement stack, first we need to create docker-composer.yml file and add all the details in it.
Once done we need to run "the stack. 

docker stack deploy -c docker-compose.yml <stackname>

docker stack ls (List out all the stacks/services delpoyed)

To modify stack (To modify number of replicas, no of instances, resourece allocation, network and storage Configuration):

    docker service ls
    docker service update --replicas=20 <service-name> (Dynmically, without updating compose file) - One way
    Or

    Go to docker stack yml file and save. once done, run 
        docker stack deploy -c docker-compose.yml <stackname>


    docker service ps <SERVICE/STACK_NAME>

    docker service update - can be used to update the network port or other settings of the deployed service


    Replicated v/s global services 

    You can define the mode of the service at the time of service Creation

    docker service create --mode = global  - It will deploye one task/service every node (One node can have multiple containers)
    for example- virus scanning, agent scanning

    docker service create --mode = replicated 



    LOGS 
    -------------------
    docker service logs

    docker service create --name <name-of-service> -p<incomingport>:<outboundport> <imagename>
    docker service create --name test-server -p8080:80 httpd

    docker service ls

    docker service logs <service-name>

    DOCKER CONTAINER NETWROKING MODEL.. ?? //NEED to READ 
    





===================================================================================================
    Chapter 3 - Docker Essential Training: 3 Image Creation, Management, and Registry
===================================================================================================

docker image ls 

docker image rm -f <image-name>

docker image prune -a (To remove all the images)


DOCKER IMAGE 
-------------
An image is an executable package that includes every thing needed 
to run an application - the code, a runtime, libraries, environment variables, configurations. files.

A container is a runtime instance of an Image.


OR an Image is a container that's not yet running.

AND A container is essentially a running image.
So you can build an image and literraly spawn thousands of containers from that.

Containers are stateless


Docker Image is made of Layer. 

Understanding Layering with docker Image

Images are made up of multiple read-only layers. Multiple containers are typically based on the same image.
When an image is instantiated into a container, a top writable image is created (which is deleted when the container is removed)
Docker manages this using STORAGE DRIVERS to manage the content of the image layers and the top writable layer. 
All drivers use stackable image layers and then a copy-on-write, or COW, strategy.

Docker Image Union Filesystem.

Image LAyers : 

                                        Other Changes
                                        application
                                        Config changes
                                        operating system 
                                        manifest



Once an image is instantiated in docker container. A writable layer is created on top of the Image in the container.

Container Layers = Image Layers + Writable Layers.

Container are stateles as the Image layers are read only and can't be modified.


Dockerfile
------------
The configuration file that build docker image is called Dockerfile

A Dockerfile is a text file that contians all the commands, in order, needed to build a given iamge. 
A Dockerfile is executed by the "docker build" command.

Dockerfile - Automate the steps of creating Docker Image.

"docker build" read the docker file and then builds a docker image based on docker file.

You can keep name anything you want, but if you do then you need to pass the file name with "docker build" command.
Without passing any name the "docker build" command will look for "Dockerfile.yml" in the same directory and with same name.


CLIENT (DOCKER CLI) ------ DOCKER HOST (DOCKER DAEMON) --- REGISTRY (DOCKERHUB)


Once you create the file. Run "docker build <DockerFileLocation>"

"docker build ." if its in the same location.

Dockerfile :

nvironment variables are supported by the following list of instructions in the Dockerfile:

ADD
COPY
ENV - Any Environment variable
EXPOSE
FROM - Which Image 
LABEL - Details 
STOPSIGNAL
USER
VOLUME
WORKDIR
RUN - Commands to run 

SAMPLE Dockerfile :
# Nginx
#
# VERSION               0.0.1

FROM      ubuntu
LABEL Description="This image is used to start the foobar executable" Vendor="ACME Products" Version="1.0"
RUN apt-get update && apt-get install -y inotify-tools nginx apache2 openssh-server


docker build . 

Once above command is executed, a new image is created. To check the newly created image run 

docker image ls 

OR 

docker image inspect <first-three-chars-of-image-id>
docker image inspect 4f4
docker image inspect 4f4 | more
OR
docker image history 4f4 (this will give you details of all the layers of the images when I was created and size of the layers )

Example :

IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
c83cd457511b        4 minutes ago       /bin/sh -c apt-get update && apt-get insta...   210 MB
c00d03324bae        10 minutes ago      /bin/sh -c #(nop)  LABEL Description=This ...   0 B
4c108a37151f        4 weeks ago         /bin/sh -c #(nop)  CMD ["/bin/bash"]            0 B
<missing>           4 weeks ago         /bin/sh -c mkdir -p /run/systemd && echo '...   7 B
<missing>           4 weeks ago         /bin/sh -c set -xe   && echo '#!/bin/sh' >...   745 B
<missing>           4 weeks ago         /bin/sh -c [ -z "$(apt-get indextargets)" ]     987 kB
<missing>           4 weeks ago         /bin/sh -c #(nop) ADD file:4e6b5d9ca371eb8...   63.2 MB


"docker image" command has various options.

C:\...\DOCKER\DockerExercise>docker image --help

Usage:  docker image COMMAND

Manage images

Options:
      --help   Print usage

Commands:
  build       Build an image from a Dockerfile
  history     Show the history of an image
  import      Import the contents from a tarball to create a filesystem image
  inspect     Display detailed information on one or more images
  load        Load an image from a tar archive or STDIN
  ls          List images
  prune       Remove unused images
  pull        Pull an image or a repository from a registry
  push        Push an image or a repository to a registry
  rm          Remove one or more images
  save        Save one or more images to a tar archive (streamed to STDOUT by default)
  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE

Run 'docker image COMMAND --help' for more information on a command.

C:\...\DOCKER\DockerExercise>


docker image prune 

   - it will removed all the dangling images (Images without TAGID/NAME)

if you want to remove all 

docker image prune -a 
    - It will remove all the unused images, that are not being used by the container.



docker image inspect <image-name>:latest --format='{{.<FieldName>}}'


docker image inspect <image-name>:latest --format='{{json .ContainerConfig}}'


docker image inspect <image-name>:latest --format='{{.ContainerConfig.HostName}}'


Docker Tag : used to identiy version of image/application.

docker image tag <tag-name/image-id> <new-name>:<tag-name>

docker image tag 6fr new-app:latest

docker image tag new-app:latest mynew-app:latest


docker build <githuburl>


docker build -f dd-docker -t ubunut:v2 . 

here "." is the build context
here "-t" is the tag name 


docker image history ubunut:v2  (it will list out all Layers of the image as a part of the build )

To minimize the Image size you can use "squash" feature.

docker build -f dd-docker --squash -t ubunut:v3 . 

Another way to reduce image size, we can use EXPORT option. Creating image into TAR by exporing a running container and then import it back


Modifying Image Layer :
-------------------------------


Tags are essentially aliases




Understanding Docker Registry
----------------------------------

Docker Registry : A Docker Registry is a stateless, highly scalable application that stores and lets you distribute Docker Images.
Registries could be local(private) or cloud-based(private or public).

Example of Docker Registries:
    - Docker Registry (Local open-source registry)

        On your local Machine. 

        $ docker run -d -p 5000:5000 --restart=always --name registry registry:2

        Once local registry is up and running, we can push any image to this registry by using 

            docker tag ubuntu localhost:5000/ubuntu:v4   (Tagged)
            docker push local:5000/ubuntu:v4 (Pushing)


        To Test this, Once image is pushed to local registry, we can delete from local 
            docker image rm localhost:5000/ubuntu:v4  (Deleted from local)
        
        Pull it back from local registry
            docker pull localhost:5000/ubuntu:v4


    - Docker Trusted Registry (DTR) Enterprise grade, higly scalable and 
        Features LDAP Integration, Image Signing, Security scanning and integration with Universal Control Plane
    
        To install DTR, first you require to install UCP (Universal Control Plane) on all the nodes where you plan to intall DTR. 

        DTR needs to be installed on a worker node that is being managed by UCP. 
        You cannot install DTR on a standalone Docker Engine.




    - Docker hub - Cloud based Docker registry

        Docker hub is a public and private registry



Anytime you go to use a registry (docker hub), first you need to login in to the registry.

    "docker login" once run, it will ask for username and password.

    You will get "Login Successed" message if its success.

    If you want to logout, then use "docker logout"

    If you want to use local deployed registry then

    docker login localhost:5000


    To login Docker trusted registry 

        docker login <DTR-HOSTNAME>, then the user credential you have 


    Pusing, pulling, and signing Images 
    ---------------------------------------

    C:\...\DOCKER\DockerExercise\dockertemp>docker tag ubuntu:latest <username>/ubuntu:latest   (TAGGING THE IMAGE)

    C:\BhopalDev\DOCKER\DockerExercise\dockertemp>docker image ls
    REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
    ubunut               v3                  644366f5d590        24 minutes ago      274 MB
    <none>               <none>              195381418de7        24 minutes ago      274 MB
    <none>               <none>              9e5ae206df0e        31 minutes ago      274 MB
    myapp                latest              c83cd457511b        About an hour ago   274 MB
    <username>/ubuntu   latest              4c108a37151f        4 weeks ago         64.2 MB
    ubuntu               latest              4c108a37151f        4 weeks ago         64.2 MB

    C:\...\DOCKER\DockerExercise\dockertemp>docker push <username>/ubuntu:latest   (PUSHING THE IMAGE)
    The push refers to a repository [docker.io/<username>/ubuntu]
    75e70aa52609: Mounted from library/ubuntu
    dda151859818: Mounted from library/ubuntu
    fbd2732ad777: Mounted from library/ubuntu
        


Docker Image Signing - Docker Enterprise Edition Only 
Docker Notary - Docker Community version- Open source but with limited features.



Searching Docker Registries
---------------------------------

docker search ubuntu - It will bring the results from the docker hub (Public only)

docker search --limit=100 ubuntu 

docker search --filter "is-official=true" ubuntu

docker search --filter "stars=100" ubuntu

docker search --filter "is-official=true"  --filter "stars=100" ubuntu

docker image ls 

It will bring the list of the images from local docker host.

===================================================================================================
    Chapter 4 - Docker Essential Training: 4 Storage and Volumes
===================================================================================================

https://docs.docker.com/storage/

Manage Data in Containers 

Issue with storing data inside containers.
    - Containers are stateless 
    - Conatiners are designed to be ephemeral
    - When containers are stopped, data is not accessible
    - Containers are typically stored on each host
    - The container filesystem was not designed for high performance I/O

Options for Data Storage with Containers:
    - Volumes (Most recommended one) 
        - The recommended way to persist data, stored at /var/lib/docker/volumes 

    - Bind Mounts
        - Have limited functionality and you must use the exact file path on the host

    - tmpfs Mounts
        - Stored only in a hosts memory in Linux (Least Recommended)


    Block v/s Object Storage 
    ----------------------------

    Block - 
        Fixed Chunks of data
        No metadata is stored
        Best for I/O intensive apps 
        SAN Storage uses block storage

    Object 
        Data is stored with metadata with a unique identifier
        There is no organization/hierarchy to the objects
        Scalability is limitless
        Accessed with HTTP Calls
        Amazon S3 Storage is an example 

    When it comes to Docker container storage infrastructures, block storage is typically used to store persistent application data, whereas object storage is typically used to store Docker container images, for example, with Docker trusted registry.

    Docker container uses a Layered storage filesystem, which honestly is a stroke of genius.


    Docker union File system 
    Docker Container 
    Container Layer 
    Writable Layer


    Docker uses what they call storage drivers to manage the contents of the image layers, as well as that top writable layer. Each storage layer has different implementation, but all drivers use this layered, stackable concept and the copy-on-write strategy. What that means is that a read-only file is only brought from the lower read-only layers into the writable layer when that file is being modified. 


    Configuring Storage Drivers
    ----------------------------------
    Storage Drivers - Overlay2 is default and preferred choice over "overlay"

    To find out existing docker storage driver, you can run "docker info"

    C:\Users\<UserName>docker info 
        Containers: 5
        Running: 0
        Paused: 0
        Stopped: 5
        Images: 8
        Server Version: 17.03.1-ce-rc1
        Storage Driver: overlay2
        Backing Filesystem: extfs
    

To change Storage Drivers:

    1. Stop the docker 
        - sudo systemctl stop docker 
    2. Take the old backup
    3. Edit /etc/docker/daemon.json and update the driver information
    4. Restart the docker 
        - sudo systemctl start docker 

Device Mapper Storage Drivers 
------------------------------
    1. Stop the docker 
        - sudo systemctl stop docker 
    2. Take the old backup
    3. Edit /etc/docker/daemon.json and update the Storage to devicemapper 
    4. Restart the docker 
        - sudo systemctl start docker 


VOLUME 
-------------------

docker volume ls (To list all the volumes )
docker volume inspect <vol-name> (Will inspect and show details about that specific volume)

 docker volume create <vol-name>
 docker volume create my-vol

 docker volume inspect my-vol
    [
        {
            "Driver": "local",
            "Labels": {},
            "Mountpoint": "/var/lib/docker/volumes/my-vol/_data",
            "Name": "my-vol",
            "Options": {},
            "Scope": "local"
        }
    ]

docker volume rm my-vol

docker run -d --name devtest --mount source=myvol2,target=/app nginx:latest


Bind Mount
----------------------

docker container run -d --mount type=bind, source=/tmp, target=/app nginx


configure docker cluster storage 
--------------------------------
 Use a volume driver ...Storage volume plugin
 Docker Volume Plugin driver

 https://thenewstack.io/methods-dealing-container-storage/
 https://dev.to/jibinliu/how-to-persist-data-in-docker-container-2m72


docker image prune - Delete all dangling container images 
docker system prune - Delete all system files..stopped container and system files being used by first_three_letter_of_image_id

C:\Users\<userId>docker system prune
WARNING! This will remove:
        - all stopped containers
        - all volumes not used by at least one container
        - all networks not used by at least one container
        - all dangling images
Are you sure you want to continue? [y/N]


===================================================================================================
    Chapter 5 - Docker Essential Training: 5 Networking
===================================================================================================

Docker network ls 


Conatiners (APP)  ---USES---- NETWORK (to perform below tasks)
                                    - Internet
                                    - Data  
                                    - End Users


Things to consider why configuring NETWORK 
    - Type of network
    - Published ports 
    - Custom DNS 
    - Load Balancing
    - Traffic Flow 
    - Logging


https://success.docker.com/article/networking


The Docker networking architecture is built on a set of interfaces called the Container Networking Model (CNM). The philosophy of CNM is to provide application portability across diverse infrastructures. This model strikes a balance to achieve application portability and also takes advantage of special features and capabilities of the infrastructure.


The Container Networking Model
 - Network Sandbox  --> Endpoints --> NETWORK (This is not physical network, its the one which is configured on the Docker Host)

        Then Network --> Docker Engine --> Network Driver or IPAM Driver --> NETWORK INFRASTRUCTURE

        IPAM - IP Addressm Management Driver 


    Native Network Driver:

        - Bridge - Connects container to the LAN and other containers .
                 --> default n/w type 

        - Host - Remove n/w isolation between container and hist.
                --> Only one container can use a port at the same time.
                --> Useful for specific applications, such as a management container that you want to run on eveyr host.

        - Overlay - Connet multiple Docker Hosts and their container together and enable swarm.
                --> Only available with Docker EE and Swarm Enabled 
                --> Multihost networking using VXLAN

        - Macvlan - Assign a MAC Address, appear as physic host.
                --> Clones host interfaces to create virtual interfaces, available in the container.
                --> Supports connecting to VLANS

        - none 

    Third Party Network Plugins :
        Examples on the Docker Store :
            - infobox IPAN Plugin
            - Weave Net
            - Contiv Network Plugin 
            https://blog.docker.com/2016/12/understanding-docker-networking-drivers-use-cases/ 


Configuring Docker Networking 
---------------------------------
docker network ls 
docker network bridge inspect 

Since "bridge" network is default one so when we do 

"docker container run", it by default go to bridge netwrok 

To create user define bridge network :

    docker network create --driver bridge <network-name>
    docker network create --driver bridge app-net 

    docker network inspect app-net  

Now spin a container with newly created bridge connection.

    docker run --name <app-name> --network <network-name> <image-name>

    docker run --name app11 --network app-net alpine ash 
    docker run --name app12 --network app-net alpine ash 

Once created. 

    docker container attach app12
        /# ping app11 
        /# ping www.google.com
        To exit from this. Press CTRL+P+Q


    docker container attach app11
        /# ping app12 
        /# ping www.google.com


docker container rm <container1>,...<container-n>

docker container rm app1 app2
docker network rm app-net 



Creating an overlay network
---------------------------------
Docker overlay network by default created if you have enabled docker swarm 

 create overlay n/w 
    docker network create --driver overlay <custom-network-name>
    docker network create --dricver overlay app-overlay 

Now deploy a service on newly created overlay network 

    docker service create --network app-overlay --name app-serv1 --replicas 6 nginx

    docker service create --network=app-overlay --name=app-serv1 --replicas=6 nginx

 I believe both of the above commads are same. Need to investigate more if there is any sort of difference here 

    docker service ls
    docker ps 
    docker ps | grep app1 

    docker service inspect app1 | more 

        Look for -  "VirtualIPs": [
                            "NetworkID":"dafdfasdf",
                            "Addr":"10.0.0.0"
                        ]


Publishing PORTS 
----------------------
To make application accessible outside the network / public network 

DOCKER HOST 
                    Exposed PORT #
        container1 ----------------->  
                                      BRIDGED NETWORK  ----------> Internal LAN / Public Network 
        container2 ----------------->
                    Exposed PORT #

To summarize above diagram we can cofirm that 

    - By default, containers are connected to the bridge network-
    - By default, containers have outbound network access but no inbound network 
    - Ports must be published to allow inbound network access 

https://docs.docker.com/engine/reference/commandline/run/


docker container run -dit -p 8080:80 nginx
    - SMALL -p means the exposed port will be selected/decided by USER 
docker container run -dit -P nginx
    - CAPITAL -P means the exposed port will be selected by DOCKER HOST 

-dit : Run it as Daemon (d) and in interactive mode (it)
-p : PORT Option 
8080 : on the host 
80 : inside the container 

docker ps 

And if you take a look on the assigned ports, it says:
    0.0.0.0:8080->80/tcp
    so here 8080 host going inside the container by port 80(inbound traffic)


Comparing HOST and INGRESS Port Publishing 

Configuring DNS in Docker 
    by passing --dns <ip-address> in the command 


To change DNS setting for all cotainers hosted on docker 

    we would edit /etc/docker/daemon.json and change 

        {
            "dns":["198.12.1.33"]
        }

sudo nano /etc/docker/daemon.json 

sudo systemctl restart docker 

DNS server details are being saved in /etc/resolv.conf of each conatners 



Configuring Load Balancing 
    https://success.docker.com/article/ucp-service-discovery


Configuring Host network - No IP is assigned and thats what make it different from other network type
    docker run --rm -d --network host --name my_nginx nginx

    https://docs.docker.com/network/network-tutorial-host/


DOCKER ARCHITECTURE AND TRAFFIC FLOW:- 

        ----------------------------------------------------
        DOCKER TRUSTER REGISTRY | CONTAINERS/APPLICATIONS
        ----------------------------------------------------
        UNIVERSAL CONTROL PLANE (UCP)
        ----------------------------------------------------
            DOCKER EE ENGINE 
        ----------------------------------------------------
        CLOUD SERVER | PHYSICAL SERVERS | VIRTUAL SERVERS
        ---------------------------------------------------



DOCKER Swarm Cluster Configuration: 

If Manager then it will have following Process components :

    MANAGER
    UCP MANAGER 
    UCP AGENT 
    DOCKER EE 

If Worker then it will have following Process components :

    WORKER 
    UCP WORKER 
    UCP AGENT 
    DOCKER EE 

https://docs.docker.com/ee/ucp/ucp-architecture/

https://docs.docker.com/ee/docker-ee-architecture/


Docker Container External PORT
---------------------------------
To know docker containers port details 

docker ps 
docker container port "container-name"

docker container port ucp-proxy
OUTPUT: 
    6444/tcp=>0.0.0.0:6444
    12378/tcp=>0.0.0.0:12378



Using logs to analyze networking issue .
--------------------------------------
    https://docs.docker.com/engine/reference/commandline/logs/


To know all the options of logs, we can check
    docker container logs --help

docker container logs <container-id>

docker container logs tdc-o3e




===================================================================================================
    Docker: Continuous Delivery
===================================================================================================





===================================================================================================
   Learning Kubernetes
===================================================================================================
 

===================================================================================================
    Kubernetes: Service Mesh with Istio
===================================================================================================
 
