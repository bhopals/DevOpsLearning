

===================================================================================================
     Learning Docker
===================================================================================================

Docker is a tool that can package an application and its dependencies in a virtual container that can run on any Linux server

Docker is a set of coupled software-as-a-service and platform-as-a-service products that use operating-system-level virtualization to develop and deliver software in packages called containers. The software that hosts the containers is called Docker Engine. 
https://labs.play-with-docker.com/


Docker is a tool that can package an application and its dependencies in a virtual container that can run on any Linux server. 


Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers. The use of Linux containers to deploy applications is called containerization. Containers are not new, but their use for easily deploying applications is.

container - A container is a runtime instance of an image



COMMANDS :

docker run <image-name>
docker ps  (will return all the running systems.)
docker ps -a (to see all the containers including stopped ones)
docker ps -l (last exited container)
docker image ls (List out all the images)

docker run <image-name> (It takes image to the container)
docker commit <container-id> (it takes container back to new image. The command will return ID)
docker tag <ID> <custom-name-of-image> (this will put the name of the newly created image)


docker container have main process. Once the process finish, container stops.

docker attach <container-name>

docker exec (Add another process to the container)


docker kill <container-name> (Kill the container)
docker rm <container-name> (Remove the container)






===================================================================================================
    Chapter 1 - Docker Essential Training: 1 Installation and Configuration
===================================================================================================

DOCKER ENGINE : 

    Client - Docker Cli - (From where you execute the command.)
    Rest API - REGISTRY (docker hub)

When you run "docker run hello-world" on the command prompt, following things happened:


To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.


Docker Universal Control Panel (UCP):
  Only comes with docker EE version (Enterprise Edition)
  It helps us to manage multiple nodes/machine with docker engine running

  UCP provides below features:
    - Private image Registry called Docker Trusted Registry
    - Secure and access use Management
    - Application and cluster Management
    - Image security scanning and continuous monitoring
    - Content trust and verification
    - Policy Management


Docker user Namespace for container isolation.
Moreover, Docker also uses CGroups (Control Groups) for controlling container resources, primarily around CPU and Memory.


To Run Ubuntu Images:
docker container run -it ubuntu



Docker Public Repository - Docker hub

To login into docker hub.

Configuration
-------------------
run "docker login"
It will ask for username and password. Once successfully logged in, pull sample images to local from public dockerhub repository.

    docker pull <image-name>
    docker pull alphine

Once the image is downloaded, you can check by running "docker images". It will list out all the images/repository.

Now we will tag the downloaded image with some other id.

    docker tag <first_three_letter_of_image_id> <username>/<image-name/repository-name>:<newtagname>

    docker tag af0 bhopalsingh/alphine:linkedtag1
    docker tag af0 bhopalsingh/alphine:linkedtag2
    docker tag af0 bhopalsingh/alphine:linkedtag3

Here we have created 3 copies of the same repository.

Now we need to push these repositories up to Docker Hub, and to do that, execute following command.

    docker push <username>/<repository-name>
    docker push bhopalsingh/alphine



To delete docker images 
    docker images (it will list out all the Images)
    docker image rm <first_three_letter_of_image_id> -f 

Once deleted, we can fetch the copy from docker hub by

    docker pull <username>/<repository-name>:<tagname>
    docker pull bhopalsingh/alphine:linkedin1

So above demo was about: (push and pull images back and forth)
    - creating a docker repositories on local
    - push the repository to docker Hub
    - pull it back to local


Docker Universal Control Plane (UCP)

To Back up DOCKER, we need to take back up of following things:

    - Docker Swarm Cluster
    - Universal Control Plane (UCP)
    - Docker Truster Registry (DTR)
    - Container Volume Data

    

Install DTR - Docker Trusted Registry

docker run -it --rm docker/dtr:2.4.12 install --ucp-insecure-tls


Some useful commands to know the staus of your docker command.

    docker info
    docker version
    docker ps
    docker ps -a 
    

===================================================================================================
    Chapter 2 - Docker Essential Training: 2 Orchestration
===================================================================================================


Docker Swarm
-----------------
Docker Swarm is open-source container orchestration platform and is the native clustering engine for and by Docker.

Docker Swarm is Cluster Management and Orchestration feature that build into the Docker Engine.

In Docker Swarm Cluster, worker nodes are being controlled by Swarm Manager Node.


To setup docker swarm cluster, "docker swarm init" command.
C:\Users\<UserName>>docker swarm init
Swarm initialized: current node (56gohlzhrnfn5z5es8ikxs90x) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-2k65k4vnr7a72cxo1jm1ir7zdf2foj82pzs8u3dueuc3f4uncm-c7xuczrsqvx70hvm8mmxhyk3k \
    192.168.65.2:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.


docker swarm join-token  = it will give you the token to use if you want to add more worker node
docker swarm join-manager= it will give you the token to use if you want to add more manager node

Now run command "docker node ls". It will list out all the nodes that are running.

C:\Users\<UserName>>docker node ls
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
56gohlzhrnfn5z5es8ikxs90x *  moby      Ready   Active        Leader



Practical:
-----------------------
Use - https://labs.play-with-docker.com
For all the practicals.

If you are getting below error in Docker lab while running "docker swarm init" command, then use the <IP-Address> flag
ERROR : docker swarm init could not choose an IP address error

docker swarm init --advertise-addr <IP-ADDRESS>


NODE / SERVICE / CONTAINER / TASKS

NODE - Node is your physical host or a virtual machine in the cloud thats running docker, the docker engine.

SERVICE - SERVICES are the instances of the image that run inside container.

    docker service create --name <app-name> --replicas=6 nginx
    docker service create --name webapp1 --replicas=6 nginx

TASK - Tasks are the container Images that are running across cluster. In a above example, TASK is  
webapp1 and CONTAINER is NGINX.

CONTAINER - Any image that you want to deploy as a service in the swarm cluster.

The container runs only on one host, the host you instantited on when you perform "docker run" command.
It will share the network and other resources per container.

CONTAINER :
    - Runs on one host
    - Must share networks and storage per container, when run
    - Containers are tough to scale and make highly available
    - COMMAND - docker run <IMAGE-NAME>
SERVICE : 
    - Automatically runs across however many nodes are needed.
    - High availabilit simply builts in.
    - COMMAND - docker service create --name <name> --replicas=6 <IMAGENAME>
    - Scalability of the app is easy
    - Exposing Network and Storage is easy


We do docker swarm init and run 3 nodes in cluster node. Then instantite nginx (a popular webserver's) 6 instances 
on all three nodes (2 instances each) in a clustered environment.

NODE1 - MANAGER  
NODE2 - WORKER 
NODE3 - WORKER
NODE4 - WORKER

docker node ls (Output all the nodes running) - (Can only be executed on manager)
docker service ls (List the service details and replicas)
docker service ps (Will return the process / services running details)

Once run, If one of the node crashed, the services instances would be created on another node instantly.


Docker services are better way to run Containers because services allow you to run containers across 
tens or hundreds of nodes in a docker swarm cluster with scalability and high availability build in.



Locking a Swarm Cluster - You can enable it by passing a parameter --autolock while initializing docker swarm.

    The locking envolves saving of the keys on the storage for communication between all the nodes in clustered environment.
    Also the logs access. To store and distribute keys across all the applications that uses docker.

    docker swarm init --autolock

For an existing docker swarm cluster which is running we use this command in MANAGER 

    docker swarm update --autolock=true 

    This will return a KEY. 


On worker node, we will simple restart all the nodes by running.
    sudo systemctl restart docker

    Now if you run command "docker node ls", it will ask for the key to unlock it.
    You can do it by running the command- "docker swarm unlock" and once prompted, enter the KEY.

To change key, we can run "docker swarm unlock-key --rotate


Quorum should be achieved in CLUSTER mode of swarm. This basically tells if you have n numbers of total nodes
then how many of the nodes would be manager to achieve less or almost zero fault tolerence.

Fault tolerance is the property that enables a system to continue operating properly in the event of the failure of (or one or more faults within) some of its components.

The Quorum algorithms basically are based on RAFT consensus Algorith.

By default Manager Nodes also shares the load of all the worked nodes, so sometimes 
if you want your manager nodes to only manage things and not involve in work load sharing then 
you need to run following command.

    docker node update --availability drain <NODE>



MANAGING DOCKER Swarm
-----------------------------------

docker node ls - List all the nodes 
docker info | more - Provide more information about the node.

If any node wants to leave the Swarm
    docker swarm leave --force

To Stop any service on docker
 
    sudo systemctl stop docker

To visualize docker swarn cluster.

    https://github.com/dockersamples/docker-swarm-visualizer
    Here have details about it. Copy the given command and paste that in one of the manager node to deploy our startup.

    docker run -it -d -p 8080:8080 -v /var/run/docker.sock:/var/run/docker.sock dockersamples/visualizer.

    Once the command is completed, please run "docker ps", you will find the visualizer in the list

    now run "ip addr" to get the ip address and get the IP address of the SERVICE. Append the port 8080 with ip address
    and run that on the browser 
    http://127.0.0.1:8080/

To convert Manager to Worker and vice versa run promote/demote command


Analyzing docker services with docker inspect
----------------------------------------------------

docker node ls - Give you the list of the nodes

Now run "docker inspect <nodename>/containerID | more"

To get specific field details you can do grep

    docker inspect <nodename>/containerID | grep Replicas

    docker inspect <containerID> | grep IPAddress




STACK 
-------------------------------
A Service defines one or more instances of a single image deployed on one or more machines (described by one entry in the services part of the docker-compose.yaml files).


A Stack defines a group of heterogeneous services (described by the whole yaml file).

A stack is a group of interrelated services that share dependencies, and can be orchestrated and scaled together. A single stack is capable of defining and coordinating the functionality of an entire application (though very complex applications may want to use multiple stacks).

To implement stack, first we need to create docker-composer.yml file and add all the details in it.
Once done we need to run "the stack. 

docker stack deploy -c docker-compose.yml <stackname>

docker stack ls (List out all the stacks/services delpoyed)

To modify stack (To modify number of replicas, no of instances, resourece allocation, network and storage Configuration):

    docker service ls
    docker service update --replicas=20 <service-name> (Dynmically, without updating compose file) - One way
    Or

    Go to docker stack yml file and save. once done, run 
        docker stack deploy -c docker-compose.yml <stackname>


    docker service ps <SERVICE/STACK_NAME>

    docker service update - can be used to update the network port or other settings of the deployed service


    Replicated v/s global services 

    You can define the mode of the service at the time of service Creation

    docker service create --mode = global  - It will deploye one task/service every node (One node can have multiple containers)
    for example- virus scanning, agent scanning

    docker service create --mode = replicated 



    LOGS 
    -------------------
    docker service logs

    docker service create --name <name-of-service> -p<incomingport>:<outboundport> <imagename>
    docker service create --name test-server -p8080:80 httpd

    docker service ls

    docker service logs <service-name>

    DOCKER CONTAINER NETWROKING MODEL.. ?? //NEED to READ 
    





===================================================================================================
    Chapter 3 - Docker Essential Training: 3 Image Creation, Management, and Registry
===================================================================================================



===================================================================================================
    Chapter 4 - Docker Essential Training: 4 Storage and Volumes
===================================================================================================


===================================================================================================
    Chapter 5 - Docker Essential Training: 5 Networking
===================================================================================================


===================================================================================================
    Docker: Continuous Delivery
===================================================================================================





===================================================================================================
   Learning Kubernetes
===================================================================================================
 

===================================================================================================
    Kubernetes: Service Mesh with Istio
===================================================================================================
 
